{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import collections\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from dataset.deepfakes_dataset import DeepFakesDataset\n",
    "from dataset.deepfakes_dataloader import get_dataloader\n",
    "from models.efficient_vit import EfficientViT\n",
    "\n",
    "from utils import (get_n_params,list_subfolder,separation_frame_video,apply_threshold,print_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"../params.yaml\", 'r') as ymlfile:\n",
    "    config = yaml.safe_load(ymlfile)\n",
    "\n",
    "if config['training']['efficient_net'] == 0:\n",
    "    channels = 1280\n",
    "else:\n",
    "    channels = 2560\n",
    "\n",
    "model = EfficientViT(config=config, channels=channels,\n",
    "                        selected_efficient_net=config['training']['efficient_net'])\n",
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint loaded.\n",
      "Model Parameters: 109447781\n"
     ]
    }
   ],
   "source": [
    "optimizer = eval(config['training']['optimizer'])\n",
    "scheduler = eval(config['training']['scheduler'])\n",
    "starting_epoch = 0\n",
    "if config['training']['resume']:\n",
    "    model.load_state_dict(torch.load(config['training']['resume']))\n",
    "    # The checkpoint's file name format should be \"checkpoint_EPOCH\"\n",
    "    starting_epoch = int(config['training']['resume'].split('/')[-1].split('_')[0].replace('epoch',''))\n",
    "    print(f\"Checkpoint loaded at {starting_epoch+1} epoch\")\n",
    "else:\n",
    "    print(\"No checkpoint loaded.\")\n",
    "\n",
    "print(\"Model Parameters:\", get_n_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = list_subfolder(config['dataset_config']['train_dir'])\n",
    "val_paths = list_subfolder(config['dataset_config']['val_dir'])\n",
    "test_paths = list_subfolder(config['dataset_config']['test_dir'])\n",
    "\n",
    "df_metadata = pd.read_csv(config['dataset_config']['labels_dataframe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 102.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 45.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 74.16it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = separation_frame_video(train_paths,df_metadata,config)\n",
    "x_val, y_val = separation_frame_video(val_paths,df_metadata,config)\n",
    "x_test, y_test = separation_frame_video(test_paths,df_metadata,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 129 Validation images: 27\n",
      "__TRAINING STATS__\n",
      "Counter({1: 99, 0: 30})\n",
      "__VALIDATION STATS__\n",
      "Counter({1: 27})\n",
      "___________________\n"
     ]
    }
   ],
   "source": [
    "# Print some useful statistics\n",
    "print(\"Train images:\", len(x_train),\n",
    "        \"Validation images:\", len(x_val))\n",
    "print(\"__TRAINING STATS__\")\n",
    "train_counters = collections.Counter(y_train)\n",
    "print(train_counters)\n",
    "\n",
    "print(\"__VALIDATION STATS__\")\n",
    "val_counters = collections.Counter(y_val)\n",
    "print(val_counters)\n",
    "print(\"___________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: BCEWithLogitsLoss()\n"
     ]
    }
   ],
   "source": [
    "loss_fn = eval(config['training']['loss'])\n",
    "print(f\"Loss function: {loss_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DeepFakesDataset(x_train,y_train,config['dataset_config']['train_transform_function'])\n",
    "val_dataset = DeepFakesDataset(x_val,y_val,config['dataset_config']['val_transform_function'])\n",
    "test_dataset = DeepFakesDataset(x_test,y_test,config['dataset_config']['val_transform_function'])\n",
    "\n",
    "train_dataloader = get_dataloader(train_dataset,config['dataset_config']['batch_size'],config['dataset_config']['workers'])\n",
    "val_dataloader = get_dataloader(val_dataset,config['dataset_config']['batch_size'],config['dataset_config']['workers'])\n",
    "test_dataloader = get_dataloader(test_dataset,config['dataset_config']['batch_size'],config['dataset_config']['workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Loss: 0.59771320 - Fake/Real Recall: 0.9798/0.0333 - Fake/Real Precision: 0.7698/0.3333 - Fake: 126/99 - Real: 3/30\n",
      "Validation Epoch: 1 - Loss: 0.36738150 - Fake/Real Recall: 1.0000/0.0000 - Fake/Real Precision: 1.0000/0.0000 - Fake: 27/27 - Real: 0/0\n",
      "\n",
      "Epoch: 2 - Loss: 0.46160096 - Fake/Real Recall: 1.0000/0.1429 - Fake/Real Precision: 0.8065/1.0000 - Fake: 62/50 - Real: 2/14"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8102/1152860788.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.train()\n",
    "model = model.cuda()\n",
    "not_improved_loss = 0\n",
    "previous_loss = np.inf\n",
    "\n",
    "MODELS_PATH = config['training']['dir_checkpoint']\n",
    "CHECKPOINT_MODELS_PATH = f\"{MODELS_PATH}/{config['training']['name_checkpoint']}\"\n",
    "\n",
    "for folder_ in [MODELS_PATH,CHECKPOINT_MODELS_PATH]:\n",
    "    if not os.path.exists(folder_):\n",
    "        os.makedirs(folder_)\n",
    "\n",
    "for epoch in range(starting_epoch+1,config['training']['num_epochs']+1):\n",
    "    if not_improved_loss == config['training']['patience']:\n",
    "        print(\"Loss did not improved, stoping training\")\n",
    "        break\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    ground_true = []\n",
    "    preds = []\n",
    "\n",
    "    for index, (images_,labels_) in enumerate(train_dataloader):\n",
    "        images = np.transpose(images_, (0, 3, 1, 2))\n",
    "        labels = labels_.unsqueeze(1)\n",
    "        images = images.cuda()\n",
    "\n",
    "        y_pred = model(images)\n",
    "        y_pred = y_pred.cpu()\n",
    "        \n",
    "        loss = loss_fn(y_pred, labels.type(torch.float32))\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        y_pred = apply_threshold(y_pred,config['training']['threshold'])\n",
    "\n",
    "        preds.extend([x[0] for x in y_pred.tolist()])\n",
    "        ground_true.extend([x[0] for x in labels.tolist()])\n",
    "\n",
    "        \n",
    "        print_information(epoch, train_loss, ground_true, preds, index)\n",
    "        \n",
    "    print(\"\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        ground_true = []\n",
    "        preds = []\n",
    "        index_ = 0\n",
    "\n",
    "        for index, (images_,labels_) in enumerate(val_dataloader):\n",
    "            index_ = index\n",
    "            images = np.transpose(images_, (0, 3, 1, 2))\n",
    "            labels = labels_.unsqueeze(1)\n",
    "            images = images.cuda()\n",
    "\n",
    "            y_pred = model(images)\n",
    "            y_pred = y_pred.cpu()\n",
    "\n",
    "            loss = loss_fn(y_pred, labels.type(torch.float32))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "            y_pred = apply_threshold(y_pred,config['training']['threshold'])\n",
    "\n",
    "            preds.extend([x[0] for x in y_pred.tolist()])\n",
    "            ground_true.extend([x[0] for x in labels.tolist()])\n",
    "\n",
    "        recall_fake, recall_real, precision_fake, precision_real = print_information(epoch, val_loss, ground_true, preds, index_,val=True)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    val_loss /= index_ + 1\n",
    "\n",
    "    if previous_loss <= val_loss:\n",
    "        print(\"Validation loss did not improved\")\n",
    "        not_improved_loss += 1\n",
    "        #pt_files = [x for x in os.listdir(CHECKPOINT_MODELS_PATH) if x.endswith('.pt')]\n",
    "    else:\n",
    "        not_improved_loss = 0\n",
    "\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            f\"{CHECKPOINT_MODELS_PATH}/epoch{epoch}_recall_fake{recall_fake}_recall_real{recall_real}_precision_fake{precision_fake}_precision_real{precision_real}.pt\"    \n",
    "        )\n",
    "\n",
    "    previous_loss = val_loss\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('deepfakes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1584a109f5336dc0eee859a1e8b6dc47623fa2e804bf7a54da8e41ac03312c16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
